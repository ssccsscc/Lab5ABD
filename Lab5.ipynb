{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK07c50i7ClQ",
        "outputId": "82207661-88ca-48db-e9d2-08d603f349db"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from pymystem3 import Mystem\n",
        "from string import punctuation\n",
        "from nltk.stem import SnowballStemmer\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "#### Часть 1 ####\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/My Drive/Lab5/lab4v2.csv\", delimiter=\",\", index_col=[0], na_values=['NA'], low_memory=False)\n",
        "\n",
        "def get_calss_name(name):\n",
        "  if \"разработчик\" in name or \"программист\" in name: return \"Разработчик\" \n",
        "  if \"менеджер\" in name or \"manager\" in name: return \"Менеджер\" \n",
        "  if \"администратор\" in name: return \"Администратор\" \n",
        "  if \"analyst\" in name or \"аналитик\" in name: return \"Аналитик\" \n",
        "  if \"художник\" in name: return \"Художник\" \n",
        "  if \"аниматор\" in name: return \"Аниматор\" \n",
        "  if \"дизайнер\" in name: return \"Дизайнер\" \n",
        "  if \"геймдизайнер\" in name: return \"Геймдизайнер\" \n",
        "  if \"devops\" in name: return \"devops\" \n",
        "  if \"тест\" in name or \"tester\" in name: return \"Тестировщик\"\n",
        "  return \"Другое\"\n",
        "\n",
        "df['Class'] = df['Vacancy Name'].apply(get_calss_name)\n",
        "\n",
        "df[\"Salary Min\"] = df.groupby([\"Class\"]).transform(lambda x: x.fillna(x.mean()))[\"Salary Min\"]\n",
        "df[\"Salary Max\"] = df.groupby([\"Class\"]).transform(lambda x: x.fillna(x.mean()))[\"Salary Max\"]\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "df['Class'] = encoder.fit_transform(df['Class'])\n",
        "f = open(\"/content/drive/My Drive/Lab5/class.txt\", \"w\")\n",
        "num = 0\n",
        "for c in encoder.classes_:\n",
        "  f.write(str(num)+\" \"+c+\"\\r\\n\")\n",
        "  num += 1\n",
        "f.close()\n",
        "#np.save('/content/drive/My Drive/Lab5/classes.npy', encoder.classes_)\n",
        "\n",
        "df = df.drop(labels=['Vacancy Name', 'City', 'Company Name', 'Date', 'Description', 'Responsibility','Requirement'], axis=1)\n",
        "\n",
        "def onehotencode(df, coln_name):\n",
        "  encoder = OneHotEncoder(sparse=False)\n",
        "  encoded = encoder.fit_transform(pd.DataFrame(df[coln_name]))\n",
        "  df = pd.concat([df.drop(coln_name, 1), pd.DataFrame(encoded, columns=encoder.get_feature_names())], axis=1).reindex()\n",
        "  return encoder, df\n",
        "\n",
        "def onehotencode_t(encoder, df, coln_name):\n",
        "  encoded = encoder.transform(pd.DataFrame(df[coln_name]))\n",
        "  df = pd.concat([df.drop(coln_name, 1), pd.DataFrame(encoded, columns=encoder.get_feature_names())], axis=1).reindex()\n",
        "  return df\n",
        "\n",
        "Expierence_encoder, df = onehotencode(df, 'Expierence')\n",
        "Employment_encoder, df = onehotencode(df, 'Employment')\n",
        "Schedule_encoder, df = onehotencode(df, 'Schedule')\n",
        "\n",
        "mystem = Mystem() \n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "russian_stopwords = stopwords.words(\"russian\")\n",
        "snowball = SnowballStemmer(language=\"russian\")\n",
        "\n",
        "def proctext(text):\n",
        "  filtered_tokens = []\n",
        "  for token in word_tokenize(text, language=\"russian\"):\n",
        "    if token not in russian_stopwords and token not in punctuation:\n",
        "        filtered_tokens.append(snowball.stem(token))\n",
        "  return ' '.join(filtered_tokens)\n",
        "\n",
        "df['Key Skills'] = df['Key Skills'].apply(proctext)\n",
        "\n",
        "text_transformer = CountVectorizer()\n",
        "text = text_transformer.fit_transform(df['Key Skills'])\n",
        "words = pd.DataFrame(text.toarray(), columns=text_transformer.get_feature_names())\n",
        "df = pd.concat([df, words], axis=1).drop(['Key Skills'], axis=1)\n",
        "\n",
        "data = df.drop(labels=['Class'], axis=1)\n",
        "target = df['Class']\n",
        "train_data, test_data, train_target, test_target = train_test_split(data, target, test_size=0.3)\n",
        "\n",
        "m = MLPClassifier(alpha=1, max_iter=1000)\n",
        "m.fit(train_data, train_target)\n",
        "print(\"MLPClassifier score: \"+str(m.score(test_data, test_target)))\n",
        "m = KNeighborsClassifier(n_neighbors=35)\n",
        "m.fit(train_data, train_target)\n",
        "print(\"KNeighborsClassifier score: \"+str(m.score(test_data, test_target)))\n",
        "m = RandomForestClassifier(n_estimators=160, max_depth=120)\n",
        "m.fit(train_data, train_target)\n",
        "print(\"RandomForestClassifier score: \"+str(m.score(test_data, test_target)))\n",
        "m = AdaBoostClassifier(n_estimators=500)\n",
        "m.fit(train_data, train_target)\n",
        "print(\"AdaBoostClassifier score: \"+str(m.score(test_data, test_target)))\n",
        "m = MultinomialNB() \n",
        "m.fit(train_data, train_target)\n",
        "print(\"MultinomialNB score: \"+str(m.score(test_data, test_target)))\n",
        "\n",
        "\n",
        "#### Часть 2 ####\n",
        "\n",
        "\n",
        "df_original = pd.read_csv(\"/content/drive/My Drive/Lab5/lab4-2v2.csv\", delimiter=\",\", index_col=[0], na_values=['NA'], low_memory=False)\n",
        "df_original = df_original.dropna(subset=['Salary Min', 'Salary Max'])\n",
        "df_original.reset_index(drop=True, inplace=True)\n",
        "df_original['Class'] = df_original['Vacancy Name'].apply(get_calss_name)\n",
        "\n",
        "df_test = pd.DataFrame(df_original)\n",
        "df_test['Class'] = encoder.transform(df_test['Class'])\n",
        "df_test = onehotencode_t(Expierence_encoder, df_test, 'Expierence')\n",
        "df_test = onehotencode_t(Employment_encoder, df_test, 'Employment')\n",
        "df_test = onehotencode_t(Schedule_encoder, df_test, 'Schedule')\n",
        "df_test = df_test.drop(labels=['Vacancy Name', 'City', 'Company Name', 'Date', 'Description', 'Responsibility','Requirement'], axis=1)\n",
        "\n",
        "df_test['Key Skills'] = df_test['Key Skills'].apply(proctext)\n",
        "text = text_transformer.transform(df_test['Key Skills'])\n",
        "words = pd.DataFrame(text.toarray(), columns=text_transformer.get_feature_names())\n",
        "df_test = pd.concat([df_test, words], axis=1).drop(['Key Skills'], axis=1)\n",
        "\n",
        "df_test_data = df_test.drop(labels=['Class'], axis=1)\n",
        "df_test_target = df_test['Class']\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=160, max_depth=120)\n",
        "model.fit(data, target)\n",
        "print(\"Result score: \"+str(model.score(df_test_data, df_test_target)))\n",
        "df_original[\"Class (predicted)\"] = model.predict(df_test_data)\n",
        "df_original[\"Class (predicted)\"] = encoder.inverse_transform(df_original[\"Class (predicted)\"].values)\n",
        "df_original[\"Class\"] = encoder.inverse_transform(df_original[\"Class\"].values)\n",
        "df_original.to_csv(\"/content/drive/My Drive/Lab5/lab5.csv\",  na_rep = 'NA', index = True, index_label = \"\", quotechar = '\"', quoting = csv.QUOTE_NONNUMERIC, encoding = \"utf-8-sig\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "MLPClassifier score: 0.5368066598073146\n",
            "KNeighborsClassifier score: 0.7748573566551304\n",
            "RandomForestClassifier score: 0.8274249368627817\n",
            "AdaBoostClassifier score: 0.5246468992610607\n",
            "MultinomialNB score: 0.3761107473575905\n",
            "Result score: 0.7356643356643356\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}